{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos vão ser treinados separadamente, ou seja, 3 modelos diferentes: LR, DM e OS.\n",
    "\n",
    "Os modelos LR e DM são independentes, isto é, LR não influencia DM e vice-versa. No entanto, OS depende dos anteriores.\n",
    "\n",
    "Para os dados de treino vão-se usar os dados de HGJ e CHUS\n",
    "Para os dados de teste vão-se usar os dados de HMR e CHUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locoregional Recurrences (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo1- ler ficheiro csv\n",
    "#Passo2- eliminar as colunas relativas a DM e OS\n",
    "#Passo3- dividir dataset em treino e teste \n",
    "#Passo4- guardar em ficheiros csv  distintos\n",
    "\n",
    "def LR():\n",
    "    Feat_Labels = pd.read_csv(\"All_Filters_Features_Clean_Normalized_Labels.csv\")\n",
    "    \n",
    "    clean_cols = Feat_Labels.drop(columns=['Distant', 'Death'])\n",
    "    \n",
    "    train_rows = clean_cols.loc[32:156]\n",
    "\n",
    "    \n",
    "    test_rows1 = clean_cols.loc[0:31]\n",
    "    test_rows2 = clean_cols.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "    \n",
    "    \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    #print(len(train_rows))\n",
    "    #print(len(test_rows1))\n",
    "    #print(len(test_rows2))\n",
    "    #print(len(test_rows))\n",
    "    train_rows.to_csv(\"All_Filters_Features_Clean_Normalized_LR_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"All_Filters_Features_Clean_Normalized_LR_test.csv\", index=False)\n",
    "    \n",
    "LR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distant Metastasis (DM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv\n",
    "#Passo2- eliminar as colunas relativas a LR e OS\n",
    "#Passo3- dividir dataset em treino e teste \n",
    "#Passo4- guardar em ficheiros csv  distintos\n",
    "\n",
    "def DM():\n",
    "    Feat_Labels = pd.read_csv(\"All_Filters_Features_Clean_Normalized_Labels.csv\")\n",
    "    \n",
    "    clean_cols = Feat_Labels.drop(columns=['Locoregional', 'Death'])\n",
    "    \n",
    "    train_rows = clean_cols.loc[32:156]\n",
    "\n",
    "    \n",
    "    test_rows1 = clean_cols.loc[0:31]\n",
    "    test_rows2 = clean_cols.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "    \n",
    "    \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    train_rows.to_csv(\"All_Filters_Features_Clean_Normalized_DM_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"All_Filters_Features_Clean_Normalized_DM_test.csv\", index=False)\n",
    "    \n",
    "DM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Survival (OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv\n",
    "#Passo2- dividir dataset em treino e teste \n",
    "#Passo3- guardar em ficheiros csv  distintos\n",
    "\n",
    "def OS():\n",
    "    Feat_Labels = pd.read_csv(\"All_Filters_Features_Clean_Normalized_Labels.csv\")\n",
    "    \n",
    "    \n",
    "    train_rows = Feat_Labels.loc[32:156]\n",
    "\n",
    "    \n",
    "    test_rows1 = Feat_Labels.loc[0:31]\n",
    "    test_rows2 = Feat_Labels.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "    \n",
    "    \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    train_rows.to_csv(\"All_Filters_Features_Clean_Normalized_OS_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"All_Filters_Features_Clean_Normalized_OS_test.csv\", index=False)\n",
    "    \n",
    "OS()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso não seja para usar a mesma divisão que Martin Vallières, a divisão em casos de treino e teste é feita aleatoriamente, estando estes no mesmo ficheiro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_1():\n",
    "    Feat_Labels = pd.read_csv(\"All_Filters_Features_Clean_Normalized_Labels.csv\")\n",
    "    \n",
    "    clean_cols = Feat_Labels.drop(columns=['Distant', 'Death'])\n",
    "    \n",
    "    clean_cols.to_csv(\"All_Filters_Features_Clean_Normalized_LR.csv\", index=False)\n",
    "    \n",
    "LR_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.read_csv('Features_Clean_Normalized.csv')\n",
    "Clinical_Data= pd.read_csv('Clinical_Data_nii_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv features + clinical data\n",
    "#Passo2- eliminar colunas no clinical data: pacientes + 4tempos + DM+ OS\n",
    "#Passo3- juntar 2 csv\n",
    "#Passo4- dividir em teste + treino\n",
    "\n",
    "\n",
    "def clinical_data_LR(Features,Clinical_Data):\n",
    "        \n",
    "    clean_data = Clinical_Data.drop(columns=['Patient','Time – diagnosis to CT sim (days)', \n",
    "                                             'Time – diagnosis to start treatment (days) ', \n",
    "                                             'Time – treatment (days)', \n",
    "                                             'Time – diagnosis to last follow-up(days)', \n",
    "                                             'Distant', 'Death'])\n",
    "    \n",
    "\n",
    "    \n",
    "    data = Features.join(clean_data, how='inner')\n",
    "    \n",
    "    print(len(data))\n",
    "    \n",
    "    \n",
    "    train_rows= data.loc[32:156]\n",
    "\n",
    "    \n",
    "    test_rows1 = data.loc[0:31]\n",
    "    test_rows2 = data.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "    \n",
    "    \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    \n",
    "    train_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_LR_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_LR_test.csv\", index=False)\n",
    "    \n",
    "clinical_data_LR(Features,Clinical_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv features + clinical data\n",
    "#Passo2- eliminar colunas no clinical data: pacientes + 4tempos + DM+ OS\n",
    "#Passo3- juntar 2 csv\n",
    "#Passo4- dividir em teste + treino\n",
    "\n",
    "\n",
    "def clinical_data_DM(Features,Clinical_Data):\n",
    "        \n",
    "    clean_data = Clinical_Data.drop(columns=['Patient','Time – diagnosis to CT sim (days)', \n",
    "                                             'Time – diagnosis to start treatment (days) ', \n",
    "                                             'Time – treatment (days)', \n",
    "                                             'Time – diagnosis to last follow-up(days)', \n",
    "                                             'Locoregional', 'Death'])\n",
    "    \n",
    "\n",
    "    \n",
    "    data = Features.join(clean_data, how='inner')\n",
    "    \n",
    "    print(len(data))\n",
    "    \n",
    "    \n",
    "    train_rows= data.loc[32:156]\n",
    "\n",
    "    \n",
    "    test_rows1 = data.loc[0:31]\n",
    "    test_rows2 = data.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "    \n",
    "    \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    \n",
    "    train_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_DM_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_DM_test.csv\", index=False)\n",
    "    \n",
    "clinical_data_DM(Features,Clinical_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv features + clinical data\n",
    "#Passo2- eliminar colunas no clinical data: pacientes + 4tempos + DM+ OS\n",
    "#Passo3- juntar 2 csv\n",
    "#Passo4- dividir em teste + treino\n",
    "\n",
    "def clinical_data_OS(Features,Clinical_Data):\n",
    "        \n",
    "    clean_data = Clinical_Data.drop(columns=['Patient','Time – diagnosis to CT sim (days)', \n",
    "                                             'Time – diagnosis to start treatment (days) ', \n",
    "                                             'Time – treatment (days)', \n",
    "                                             'Time – diagnosis to last follow-up(days)'])\n",
    "    \n",
    "    data = Features.join(clean_data, how='inner')\n",
    "       \n",
    "    train_rows= data.loc[32:156]\n",
    "   \n",
    "    test_rows1 = data.loc[0:31]\n",
    "    test_rows2 = data.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "       \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    \n",
    "    train_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_OS_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_OS_test.csv\", index=False)\n",
    "    \n",
    "clinical_data_OS(Features,Clinical_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Data - with time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = pd.read_csv('Features_Clean_Normalized.csv')\n",
    "Clinical_Data= pd.read_csv('Clinical_Data_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv features + clinical data\n",
    "#Passo2- eliminar colunas no clinical data: pacientes + 4tempos + DM+ OS\n",
    "#Passo3- juntar 2 csv\n",
    "#Passo4- dividir em teste + treino\n",
    "\n",
    "\n",
    "def clinical_data_LR(Features,Clinical_Data):\n",
    "        \n",
    "    clean_data = Clinical_Data.drop(columns=['Patient','Time – diagnosis to CT sim (days)', 'Distant', 'Death'])\n",
    "    \n",
    "\n",
    "    \n",
    "    data = Features.join(clean_data, how='inner')\n",
    "    \n",
    "    print(len(data))\n",
    "    \n",
    "    \n",
    "    train_rows= data.loc[32:156]\n",
    "\n",
    "    \n",
    "    test_rows1 = data.loc[0:31]\n",
    "    test_rows2 = data.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "    \n",
    "    \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    \n",
    "    train_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_time_LR_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_time_LR_test.csv\", index=False)\n",
    "    \n",
    "clinical_data_LR(Features,Clinical_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv features + clinical data\n",
    "#Passo2- eliminar colunas no clinical data: pacientes + 4tempos + DM+ OS\n",
    "#Passo3- juntar 2 csv\n",
    "#Passo4- dividir em teste + treino\n",
    "\n",
    "\n",
    "def clinical_data_DM(Features,Clinical_Data):\n",
    "        \n",
    "    clean_data = Clinical_Data.drop(columns=['Patient','Time – diagnosis to CT sim (days)', 'Locoregional', 'Death'])\n",
    "    \n",
    "\n",
    "    \n",
    "    data = Features.join(clean_data, how='inner')\n",
    "    \n",
    "    print(len(data))\n",
    "    \n",
    "    \n",
    "    train_rows= data.loc[32:156]\n",
    "\n",
    "    \n",
    "    test_rows1 = data.loc[0:31]\n",
    "    test_rows2 = data.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "    \n",
    "    \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    \n",
    "    train_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_time_DM_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_time_DM_test.csv\", index=False)\n",
    "    \n",
    "clinical_data_DM(Features,Clinical_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "32\n",
      "38\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "#Passo1- ler ficheiro csv features + clinical data\n",
    "#Passo2- eliminar colunas no clinical data: pacientes + 4tempos + DM+ OS\n",
    "#Passo3- juntar 2 csv\n",
    "#Passo4- dividir em teste + treino\n",
    "\n",
    "def clinical_data_OS(Features,Clinical_Data):\n",
    "        \n",
    "    clean_data = Clinical_Data.drop(columns=['Patient','Time – diagnosis to CT sim (days)'])\n",
    "    \n",
    "    data = Features.join(clean_data, how='inner')\n",
    "       \n",
    "    train_rows= data.loc[32:156]\n",
    "   \n",
    "    test_rows1 = data.loc[0:31]\n",
    "    test_rows2 = data.loc[157:]\n",
    "    \n",
    "    test_rows3 = [test_rows1, test_rows2]\n",
    "       \n",
    "    test_rows = pd.concat(test_rows3)\n",
    "    \n",
    "    print(len(train_rows))\n",
    "    print(len(test_rows1))\n",
    "    print(len(test_rows2))\n",
    "    print(len(test_rows))\n",
    "    \n",
    "    train_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_time_OS_train.csv\", index=False)\n",
    "    test_rows.to_csv(\"Features_Clean_Normalized_Clinical_Data_time_OS_test.csv\", index=False)\n",
    "    \n",
    "clinical_data_OS(Features,Clinical_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
